<!DOCTYPE html><html lang="zh-cn"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>RPC服务追踪的原理与实践 | ShareCore</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.1.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.2/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.3/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">RPC服务追踪的原理与实践</h1><a id="logo" href="/.">ShareCore</a><p class="description">Justin.H</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首頁</i></a><a href="/archives/"><i class="fa fa-archive"> 所有文章</i></a><a href="http://weibo.com/justinhuang"><i class="fa fa-user"> 關於</i></a><a href="/atom.xml"><i class="fa fa-rss"> 訂閱</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">RPC服务追踪的原理与实践</h1><div class="post-meta">Mar 9, 2017<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><p>在分布式服务化架构下，由于分布式服务间存在相互依赖，彼此协同来完成各类业务场景。下图是一个典型的业务场景，从前端发起一个请求，到最后的业务完成，需要经过很多环节，这些环节可能都是分布式服务的方式提供，部署在不同的服务器上进行。而在这种复杂的分布式服务场景下，为了定位问题、性能瓶颈查询、异常日志跟踪等，如果没有服务追踪和分析工具的帮助，都是非常困难的。<br><img src="/images/trace/trace.png" style="width:500px"><br>说到分布式追踪，当然不得不提Google为其基于日志的分布式跟踪系统Dapper发表的[论文]，在这边论文里，Google介绍了他们在分布式追踪领域的经验，总体来看其核心概念有三个：<br><strong>1. TraceID：用来标识每一条业务请求链的唯一ID，TraceID需要在整个调用链路上传递</strong><br><strong>2. Span：请求链中的每一个环节为一个Span，每一个Span有一个SpanId来标识，前后Span间形成父子关系</strong><br><strong>3. Annotation：业务自定义的埋点信息，可以是sql、用户ID等关键信息</strong><br><img src="/images/trace/span.png" style="width:500px"><br><em>图：5个span在Dapper跟踪树中的关联关系(图来自google论文)</em></p>
<p>Google论文出来后，业界出现了很多基于其思想实现的开源框架，如Twitter的zipkin，其中zipkin是严格按照来Dapper论文来设计的，他提供了完整的跟踪记录收集、存储功能，以及查询API与界面。其存储支持多种数据库：MySql、ElasticSearch、Cassandra、Redis等等，收集API支持HTTP和Thrift。<br><img src="/images/trace/zipkin.png" style="width:500px"><br>但作为服务跟踪中最难处理的一环，即跟踪埋点，zipkin并没有提供，需要使用方自己实现。业界也有Brave这样的开源项目可以使用，但是评估过后，发现Brave的实现过于复杂，依赖组件也过多，并且其实现的组件更多是支持HTTP服务的调用，对于我们的Thrift RPC服务不能支持，所以没有使用Brave，改为自己实现。自己实现服务埋点和追踪有几个问题需要解决：</p>
<h3 id="1-_TraceID如何生成？">1. TraceID如何生成？</h3><p>由于要唯一标示每一次调用，所以TraceID需要保证全局唯一。唯一的ID，第一个想到的当然是使用UUID，UUID是一个较为高效又使用方便的唯一ID生成方式，但问题是，zipkin要求TraceID是int64类型，不能是字符串，同时，UUID还有一个问题是不能保证单调有序。对此，有两个架构方案可选：<br><strong>- 使用数据库自增长ID来生成，同时需要解决以下问题：</strong></p>
<ul>
<li>性能上，如果每次请求都访问数据库一次，会带来较大的性能损失，所以需要在客户端缓存一个区间的数字，当这个区间的数字不够时再从数据库获取。</li>
<li>出于安全要求不能跟数据库直连的客户端不适合，如Web服务器。可以考虑使用一个中间服务作为ID分发。<br>结合上面两点要求，架构方案如下：<br><img src="/images/trace/id.png" style="width:500px"><br>此方案中，ID分发服务的高可用性要求很高，如果该服务出现不可用，将影响到所有服务均不可用，增加了后续运营维护的麻烦。</li>
</ul>
<p><strong>- 采用分机器(进程)的方式，保证机器间(进程间)ID不冲突，同时保证单机器(进程)内ID是递增不重复的。</strong>这种方式的最大好处时不需要中心化的节点进行ID分发，省掉了系统间的依赖。对于此种方案，最常用的算法是<strong>Twitter-Snowflake</strong>算法，也是我们最终选择的算法。<strong>Snowflake核心思想是将int64的除第一位外的其他63位分成三段，前面41位为时间戳、后面10位为工作机器(进程)ID，也称为WorkerID ，最后12位为递增序列号。</strong><br>(img)<br>当然，以上长度分段只是默认，可以根据实际情况进行区分，比如41位的时间戳，最长可以用<code>(-1L ^ -1L&lt;&lt;41)/(3600 * 24 * 365 * 1000)</code>=69年，10位的WorkerID最多支持1023台机器(进程)，12位为递增序列表示每毫秒最多4095个ID，在实际中，我们为了支持更多的机器(进程)，采取了16位WorkerID，4位标识序列号，即最多支持65535台机器(进程)，每毫秒最多生成15个ID。该方案中，WrokerID的分配是需要特别注意的，<strong>WorkerID应该每个进程唯一，不能相同，如果相同的话就会出现低概率的ID重复</strong>。</p>
<p>分配WorkerID最简单的办法是采取配置的方式，将WorkerID配置到程序的配置文件，但这种方式运营部署起来很麻烦，也容易沟通不到位，导致配置错误或重复。所以我们采取了通过Zookeeper动态分配WorkerID的方案，即在程序启动时，向Zookeeper发起请求，找到一个可用的WorkerID，如果找到一个可用的WorkerID，即创建一个临时子节点，利用Zookeeper临时节点可以自动释放的特性，当程序关闭时，该WorkerID就自动释放了，以达到了WorkerID的重用。只在进程启动时，访问一次Zookeeper来获取WorkeID，所以运行时不需要Zookeeper持续提供服务，性能也不会有损失。</p>
<h3 id="2-_数据埋点如何做到对业务开发透明？如何在当前上下文中记录信息">2. 数据埋点如何做到对业务开发透明？如何在当前上下文中记录信息</h3><p>所谓数据埋点，即将跟踪信息(TraceID、Span信息等)写入服务调用的上下文中，如果这个交给业务代码来完成的话，会导致业务代码变得冗余，同时如果业务代码忘记埋点，那就会丢失跟踪信息，所以在底层框架提供数据埋点，非常有必要。<br>数据埋点主要包括四个阶段：</p>
<ul>
<li><strong>Client Send</strong>：客户端发起请求时，如果当前线程上下文已经有Trace信息，继续透传当前Trace信息，如果没有，表示一个信息的请求，生成信息的Trace信息进行传递。</li>
<li><strong>Server Recieve</strong>: 服务端接收到请求时间点，此时从当前请求里获取Trace信息，并将当前信息存入线程上下文。</li>
<li><strong>Server Send</strong>：服务端处理业务完成，准备返回响应时，标记业务处理完成，同时将当前Trace信息提交归档。</li>
<li><strong>Client Receive</strong>：客户端接收到服务端响应时，标记服务调用完成，同时将当前Trace信息提交归档。</li>
</ul>
<p>如下的流程示例图说明各阶段埋点的位置，其中<strong>CS、SR为发起创建Trace信息到当前线程上下文的位置，CR、SS为归档提交Trace信息的位置</strong>。<br><img src="/images/trace/trace1.png" style="width:500px"><br>以上解释了在什么地方埋点和收集Trace信息，但是如何将当前上下文中的信息进行临时存储，并保证线程安全呢？这一点可以借助ThreadLocal来完成，发起创建Trace信息时，往ThreadLocal中写入记录，当前请求过程中再发起新的请求时，从ThreadLocal中获取Trace信息继续往下传递，等信息可以提交归档的时候，从ThreadLocal读取，并清除ThreadLocal中的信息。但是有一个问题需要注意，<strong>当发起异步请求时，发起请求的线程和最终被服务响应锁唤起的线程不是同一个线程，对于这种情况，如果响应线程是可由当前线程创建，使用可继承InheritableThreadLocal即可，如果不是，如由线程池来创建，则需要实现特别的线程池管理</strong>。另外还有一个办法就是，如果异步回调代码是可以注入的，那我们就可以在发起响应回调的时候注入代码即可。我们的RPC Client里就是采取这种方式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">AsyncMethodCallback callback=<span class="keyword">new</span> AsyncMethodCallback() &#123;</span><br><span class="line">	<span class="annotation">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">	    <span class="keyword">if</span> (transport != <span class="keyword">null</span>) &#123;</span><br><span class="line">	        closeTransport(url,transport);</span><br><span class="line">	    &#125;</span><br><span class="line">	    <span class="comment">//注入trace跟踪处理</span></span><br><span class="line">	    Tracer.appendSpan(spanInfo);</span><br><span class="line">	    Tracer.addAannotation(serviceName, url.getIpByInt(), url.getPort(), AnnotationNames.CLIENT_RECV);</span><br><span class="line">	    Tracer.submitCurrentSpan();</span><br><span class="line">	    <span class="comment">//执行业务回调</span></span><br><span class="line">	    resultHandler.onComplete(o);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>同时，这里有个性能优化点需要注意，当Trace信息可以归档提交时，并不是往zipkin中直接写入，因为zipkin的性能有限，同时网络开销也较大，可以采取异步提交zipkin的方式，<strong>客户端归档信息后先从上下文往当前内存队列里写入，然后由单独的线程向zipkin提交记录。</strong></p>
<h3 id="3-_怎么实现Trace信息在调用链上的传递？">3. 怎么实现Trace信息在调用链上的传递？</h3><p>前文说到，服务追踪的核心是将Trace信息(TraceID、SpanID)在整个调用链上进行传递，而这些类似上下文的信息，一般不适合作为参数置于服务调用方法里进行传递。如果是HTTP调用，我们可以用HTTP Header来传递信息是非常方便的，但是Thrift服务并没有所谓的Header信息可以传递。<br>通过研究Thrift代码，发现在Thrift的传输协议实现里，服务端读取数据反序列化协议的入口方法是：<br><code>public abstract TMessage readMessageBegin() throws TException;</code><br>返回的TMessage对象中，有一个name的属性，其存储的是需要调用的服务方法名，比如我们调用：UserService.getUser(1)，那这里的name属性值就是“getUser”。既然这里name可以传递一个公用的字符串，那我们自然可以在此进行扩展，在name属性上传递更多信息。将name按一个文本格式协议，组装成一个header信息进行传递。</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//读取消息头</span></span><br><span class="line">TMessage message = iprot.readMessageBegin();</span><br><span class="line"><span class="comment">// 提取Header文本</span></span><br><span class="line"><span class="keyword">int</span> index = message.name.lastIndexOf(TMultiplexedProtocol.SEPARATOR);</span><br><span class="line">String headersValue = message.name.substring(<span class="number">0</span>, index);</span><br><span class="line"><span class="comment">//采取Http Header文本格式传递</span></span><br><span class="line">Headers headers = Headers.parseHeaders(headersValue);</span><br><span class="line">String traceID = headers.get(Constants.TPROTOCOL_HEADER_TRACE_ID);<span class="comment">//arr[1];</span></span><br><span class="line">String spanID = headers.get(Constants.TPROTOCOL_HEADER_SPAN_ID);<span class="comment">//arr[2];</span></span><br><span class="line">....</span><br><span class="line"><span class="comment">//将message.name还原，继续走thrift标准处理流程</span></span><br><span class="line"><span class="keyword">int</span> len = headersValue.length() + TMultiplexedProtocol.SEPARATOR.length();</span><br><span class="line">String methodName = message.name.substring(len);</span><br><span class="line">TMessage standardMessage = <span class="keyword">new</span> TMessage(</span><br><span class="line">	methodName,</span><br><span class="line">	message.type,</span><br><span class="line">	message.seqid</span><br><span class="line">	);</span><br><span class="line">actualProcessor.process(<span class="keyword">new</span> SomeProtocol(standardMessage))</span><br></pre></td></tr></table></figure>
<p>关于此种扩展方式，Thrift标准库为了实现同一个server里host多个服务Processor，也采取了这种方式，只是标准库只扩展了一个ServiceName字段进行传递而已。具体可以参考Thrift标准库的TMultiplexedProtocol 与TMultiplexedProcessor的代码。</p>
<h2 id="总结：">总结：</h2><p>本文介绍了从原理到实现上介绍了如何实现RPC服务追踪的细节，其关键基于调用链的概念。但是在实现上为了做到业务开发透明，还要不影响业务性能，还是需要很多谨慎考虑的。同时，我们其实还有很多未尽事宜需要继续优化，如提供安全的、埋点Tarce上下文的线程池，提供其他多种埋点客户端等等。同时，当Trace信息变成海量后，怎么存储这些信息，以及快速分析，从中挖取更多有意义、有价值的信息，将会成为我们新的挑战。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://sharecore.net/2017/03/09/RPC服务追踪的原理与实践/" data-id="cjfkvakoz002s4nvjtb2u3ror" class="article-share-link">分享至</a><div class="tags"><a href="/tags/技术/">技术</a><a href="/tags/架构/">架构</a></div><div class="post-nav"><a href="/2017/05/07/GC知识笔记/" class="pre">JVM GC知识笔记</a><a href="/2016/11/01/分布式锁进阶1-基础/" class="next">分布式锁进阶1-基础</a></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://sharecore.net"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分類</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 標籤</i></div><div class="tagcloud"><a href="/tags/基础知识/" style="font-size: 15px;">基础知识</a><a href="/tags/常识/" style="font-size: 15px;">常识</a><a href="/tags/技术常识/" style="font-size: 15px;">技术常识</a><a href="/tags/架构/" style="font-size: 15px;">架构</a><a href="/tags/算法/" style="font-size: 15px;">算法</a><a href="/tags/历史/" style="font-size: 15px;">历史</a><a href="/tags/学习/" style="font-size: 15px;">学习</a><a href="/tags/服务化/" style="font-size: 15px;">服务化</a><a href="/tags/技术/" style="font-size: 15px;">技术</a><a href="/tags/模式匹配/" style="font-size: 15px;">模式匹配</a><a href="/tags/春秋/" style="font-size: 15px;">春秋</a><a href="/tags/Golang/" style="font-size: 15px;">Golang</a><a href="/tags/读书/" style="font-size: 15px;">读书</a><a href="/tags/测试/" style="font-size: 15px;">测试</a><a href="/tags/复杂性/" style="font-size: 15px;">复杂性</a><a href="/tags/Linux/" style="font-size: 15px;">Linux</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/04/02/Jarvis异步任务平台介绍/">Jarvis异步任务平台介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/07/GC知识笔记/">JVM GC知识笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/09/RPC服务追踪的原理与实践/">RPC服务追踪的原理与实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/01/分布式锁进阶1-基础/">分布式锁进阶1-基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/16/懷才不遇/">懷才不遇？</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/27/讀張五常談思考方法/">讀張五常談思考方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/22/超越辯論的價值/">超越辯論的價值</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/20/電子閱讀的問題反思/">電子閱讀的問題反思</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/20/讀點王陽明/">讀點王陽明</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/17/文字之殤/">文字之殤</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友站連結</i></div><ul></ul><a href="http://weibo.com/justinhuang" title="微博" target="_blank">微博</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">ShareCore.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-37230829-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>